{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para este laboratorio, hemos decidido usar un dataset con los tweets que realizaron las personas frente a Apple</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del archivo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Apple-Twitter-Sentiment-DFE.csv\", header=0,encoding = 'utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>623497979</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/11/14 20:55</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sat Dec 06 14:39:19 +0000 2014</td>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve Jobs defends Apple from the grave in iPo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>623498734</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 1:58</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mon Dec 08 21:55:10 +0000 2014</td>\n",
       "      <td>5.420000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @HorseshoeBmore #Holiday #Giveaway! To ensu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>623497512</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 21:36</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fri Dec 05 13:43:32 +0000 2014</td>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When a company is playing catch-up, it lost it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>623498896</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/11/14 21:21</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tue Dec 09 01:28:24 +0000 2014</td>\n",
       "      <td>5.420000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TeamCavuto: Protesters stage #DieIn protes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>623496352</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 2:56</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wed Dec 03 16:27:41 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBI investigates iPad school programme $AAPL #...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "2449  623497979    False   finalized                   3    12/11/14 20:55   \n",
       "3204  623498734    False   finalized                   3     12/12/14 1:58   \n",
       "1987  623497512    False   finalized                   3    12/12/14 21:36   \n",
       "3366  623498896    False   finalized                   3    12/11/14 21:21   \n",
       "839   623496352    False   finalized                   3     12/12/14 2:56   \n",
       "\n",
       "     sentiment  sentiment:confidence                            date  \\\n",
       "2449         3                   1.0  Sat Dec 06 14:39:19 +0000 2014   \n",
       "3204         3                   1.0  Mon Dec 08 21:55:10 +0000 2014   \n",
       "1987         1                   1.0  Fri Dec 05 13:43:32 +0000 2014   \n",
       "3366         3                   1.0  Tue Dec 09 01:28:24 +0000 2014   \n",
       "839          3                   1.0  Wed Dec 03 16:27:41 +0000 2014   \n",
       "\n",
       "                id            query sentiment_gold  \\\n",
       "2449  5.410000e+17  #AAPL OR @Apple            NaN   \n",
       "3204  5.420000e+17  #AAPL OR @Apple            NaN   \n",
       "1987  5.410000e+17  #AAPL OR @Apple            NaN   \n",
       "3366  5.420000e+17  #AAPL OR @Apple            NaN   \n",
       "839   5.400000e+17  #AAPL OR @Apple            NaN   \n",
       "\n",
       "                                                   text  \n",
       "2449  Steve Jobs defends Apple from the grave in iPo...  \n",
       "3204  RT @HorseshoeBmore #Holiday #Giveaway! To ensu...  \n",
       "1987  When a company is playing catch-up, it lost it...  \n",
       "3366  RT @TeamCavuto: Protesters stage #DieIn protes...  \n",
       "839   FBI investigates iPad school programme $AAPL #...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que no aportan informacion en cuanto al sentimiento dentro del texto. Estas columnas son las fechas, identificadores y estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_golden</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Apple to Open New Research Site in Japan - WS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @mrushh: hey @apple why is my phone dying w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8078</td>\n",
       "      <td>3\\r\\nnot_relevant</td>\n",
       "      <td>@iamrayuko @Apple who're you talking to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @OneRepublic: Studio at 45,000 ft.  One out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TeamCavuto: Protesters stage #DieIn protes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _golden  _trusted_judgments sentiment  sentiment:confidence  \\\n",
       "3653    False                   3         5                0.6773   \n",
       "2303    False                   3         1                1.0000   \n",
       "3837     True                  15         3                0.8078   \n",
       "1629    False                   3         1                0.7079   \n",
       "3303    False                   3         5                0.6635   \n",
       "\n",
       "         sentiment_gold                                               text  \n",
       "3653                NaN  @Apple to Open New Research Site in Japan - WS...  \n",
       "2303                NaN  RT @mrushh: hey @apple why is my phone dying w...  \n",
       "3837  3\\r\\nnot_relevant            @iamrayuko @Apple who're you talking to  \n",
       "1629                NaN  RT @OneRepublic: Studio at 45,000 ft.  One out...  \n",
       "3303                NaN  RT @TeamCavuto: Protesters stage #DieIn protes...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop([\"_unit_id\",\"_unit_state\",\"date\",\"id\",\"query\",\"_last_judgment_at\"],axis=1)\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos la columna \"sentiment\" que es el dato final que queremos lograr. Además dividimos los datos de forma que el 80% de los datos servirá para entrenar y el 20% restante servirá para probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = df2.drop(['sentiment'],axis=1)\n",
    "y_all = df2['sentiment']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_test = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3657    @TeamCavuto @CaliCard1 @Apple It's not handled...\n",
      "605     Move Aside #Apple and #Google, #Alibaba is Ent...\n",
      "3260    Completely in love with my @apple #iphone6 rig...\n",
      "3841    RT @iLoveMyMom98: I've tried turning it off an...\n",
      "324     #Apple lower following cautious Pac Crest, Deu...\n",
      "3599    RT @Amdocs: Top #iOS apps of 2014. @Apple name...\n",
      "3087    fucking @apple are memer FAGGOTS http://t.co/w...\n",
      "663     The U.S. government accepts donations to reduc...\n",
      "2694    @YogscastSjin WOW!! The yogscast is now even s...\n",
      "152     RT @donacamp: Brass band at @Apple Store Broad...\n",
      "3834    .@Apple please ban 'After School' and 'Yik Yak...\n",
      "1917    @Apple Watch SDK and #Monetizaton: Why You Sho...\n",
      "394     Hey @apple: Love ya but #AppleCare low-fi hold...\n",
      "2676    Apple Acted Unfairly In Suppressing Digital Mu...\n",
      "2490                 @lanadelreystan KILL YOURSELF @apple\n",
      "3851                              @nialIhburn @Apple TRES\n",
      "3694                                     .@apple you suck\n",
      "2989    Woah. Woke up to 20+ @apple emails of someone ...\n",
      "1364    .@codeorg it looks like @Apple is offering a f...\n",
      "3132    NO CALLER ID must be able to be BLOCKED on @Ap...\n",
      "3796    @apple @tim_cook its 28 mb ! Why do i need WiF...\n",
      "3570    RT @SwiftKey: We're so excited to be named to ...\n",
      "3843    @iamrayuko @Apple because you know you don't w...\n",
      "1389    RT @JPDesloges: Apple Pay And Services Lead To...\n",
      "3832    had android chargers for years &amp; they're s...\n",
      "778     @jakeflem @Apple I had to get my logic board c...\n",
      "3789    Apple Transitions 'Find My iPhone' Web Maps fo...\n",
      "1579    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "2730    @Apple yo this Genius Bar shit is worst than t...\n",
      "957     Apple's iPhone Gained Significant Share In The...\n",
      "                              ...                        \n",
      "3109    @Apple [#Apple] #Names Its Best #iPhone and #i...\n",
      "3699    Apple 'hoarding' iPhone 6 supply for its own s...\n",
      "379     Late Apple Inc. Co-Founder Steve Jobs 'Testifi...\n",
      "2696    'This accessory may not be supported' ok @Appl...\n",
      "1694    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "844                why isn't there a dreidel emoji @apple\n",
      "1081    Apple Secretly Deleted iPod Owners' Songs Down...\n",
      "876     @thehill @Apple @tim_cook @WhiteHouse @jmhatte...\n",
      "4            Nobody expects the Spanish Inquisition #AAPL\n",
      "1594    '@OneRepublic: Studio at 45,000 ft.  One outle...\n",
      "1437    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "3384    RT @TeamCavuto: Protesters stage #DieIn protes...\n",
      "1635    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "199     iPad Mini First Time Startup!: http://t.co/vGH...\n",
      "916     Is It Time to Buy the Dip in #Apple Inc. Stock...\n",
      "3466    @TeamCavuto @stuntbrain @Apple No rule against...\n",
      "253     Apple Lower as Analyst Sees Risk of Sharp Prod...\n",
      "3561    Apple: $113 matches 8% increase in earnings. 2...\n",
      "2777    Cool Stuff Found: @Apple Posts 'iPad Air 2 - C...\n",
      "3402    @Listen2Lena 3x bonus airmiles @Apple right no...\n",
      "2571    Finally updated to iOS 8...this happened ha we...\n",
      "279     Apple Inc. is doomed. $AAPL dropped by 1.54%! ...\n",
      "44      Ok, @apple. You win. I won't use your browser ...\n",
      "1658    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "621     Liberals should protest corporate greed and th...\n",
      "3827                  @StepRam @Apple is it your mother's\n",
      "3463              Why does my battery die so quick @apple\n",
      "3615    Apple Plans to Launch iPhone 6 Mini Version in...\n",
      "1591    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "2903    RT @fakebananas: Thanks @Apple for the preview...\n",
      "Name: text, Length: 3108, dtype: object\n",
      "Move Aside #Apple and #Google, #Alibaba is Entering the Connected Car Space - Forbes #baba #goog #aapl http://t.co/gOSQlrWvtl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "titles =np.array(X_train[\"text\"])\n",
    "print(X_train[\"text\"])\n",
    "print(titles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "text = \" \".join(titles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text=titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txd_matrix = vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 7326)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txd_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 865)\t1\n",
      "  (0, 2883)\t1\n",
      "  (0, 5818)\t1\n",
      "  (0, 5784)\t1\n",
      "  (0, 1811)\t1\n",
      "  (0, 2796)\t1\n",
      "  (0, 2292)\t1\n",
      "  (0, 6384)\t1\n",
      "  (0, 2018)\t1\n",
      "  (0, 4393)\t1\n",
      "  (0, 3929)\t1\n",
      "  (0, 2636)\t1\n",
      "  (0, 1214)\t1\n",
      "  (0, 6967)\t1\n",
      "  (0, 3023)\t1\n",
      "  (0, 4533)\t2\n",
      "  (0, 3513)\t1\n",
      "  (0, 700)\t1\n",
      "  (0, 1252)\t1\n",
      "  (0, 6269)\t1\n",
      "  (1, 2911)\t1\n",
      "  (1, 1490)\t1\n",
      "  (1, 3216)\t1\n",
      "  (1, 438)\t1\n",
      "  (1, 2898)\t1\n",
      "  :\t:\n",
      "  (3106, 4667)\t1\n",
      "  (3106, 808)\t1\n",
      "  (3106, 4623)\t1\n",
      "  (3106, 5543)\t1\n",
      "  (3106, 4549)\t1\n",
      "  (3106, 1490)\t1\n",
      "  (3106, 3216)\t1\n",
      "  (3106, 6348)\t2\n",
      "  (3106, 700)\t1\n",
      "  (3107, 6885)\t1\n",
      "  (3107, 3451)\t1\n",
      "  (3107, 5213)\t1\n",
      "  (3107, 2578)\t1\n",
      "  (3107, 5045)\t1\n",
      "  (3107, 2440)\t1\n",
      "  (3107, 6341)\t1\n",
      "  (3107, 5870)\t1\n",
      "  (3107, 7247)\t1\n",
      "  (3107, 2648)\t1\n",
      "  (3107, 4623)\t1\n",
      "  (3107, 5543)\t1\n",
      "  (3107, 1490)\t1\n",
      "  (3107, 3216)\t1\n",
      "  (3107, 6348)\t1\n",
      "  (3107, 700)\t1\n"
     ]
    }
   ],
   "source": [
    "print (txd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txd_matrix = CountVectorizer(binary=True).fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 865)\t1\n",
      "  (0, 2883)\t1\n",
      "  (0, 5818)\t1\n",
      "  (0, 5784)\t1\n",
      "  (0, 1811)\t1\n",
      "  (0, 2796)\t1\n",
      "  (0, 2292)\t1\n",
      "  (0, 6384)\t1\n",
      "  (0, 2018)\t1\n",
      "  (0, 4393)\t1\n",
      "  (0, 3929)\t1\n",
      "  (0, 2636)\t1\n",
      "  (0, 1214)\t1\n",
      "  (0, 6967)\t1\n",
      "  (0, 3023)\t1\n",
      "  (0, 4533)\t1\n",
      "  (0, 3513)\t1\n",
      "  (0, 700)\t1\n",
      "  (0, 1252)\t1\n",
      "  (0, 6269)\t1\n",
      "  (1, 2911)\t1\n",
      "  (1, 1490)\t1\n",
      "  (1, 3216)\t1\n",
      "  (1, 438)\t1\n",
      "  (1, 2898)\t1\n",
      "  :\t:\n",
      "  (3106, 4667)\t1\n",
      "  (3106, 808)\t1\n",
      "  (3106, 4623)\t1\n",
      "  (3106, 5543)\t1\n",
      "  (3106, 4549)\t1\n",
      "  (3106, 1490)\t1\n",
      "  (3106, 3216)\t1\n",
      "  (3106, 6348)\t1\n",
      "  (3106, 700)\t1\n",
      "  (3107, 6885)\t1\n",
      "  (3107, 3451)\t1\n",
      "  (3107, 5213)\t1\n",
      "  (3107, 2578)\t1\n",
      "  (3107, 5045)\t1\n",
      "  (3107, 2440)\t1\n",
      "  (3107, 6341)\t1\n",
      "  (3107, 5870)\t1\n",
      "  (3107, 7247)\t1\n",
      "  (3107, 2648)\t1\n",
      "  (3107, 4623)\t1\n",
      "  (3107, 5543)\t1\n",
      "  (3107, 1490)\t1\n",
      "  (3107, 3216)\t1\n",
      "  (3107, 6348)\t1\n",
      "  (3107, 700)\t1\n"
     ]
    }
   ],
   "source": [
    "print(txd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_matrix = TfidfVectorizer(use_idf=False).fit_transform(text)\n",
    "tfidf_matrix = TfidfVectorizer().fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 7326)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 865)\t0.208514414057\n",
      "  (0, 2883)\t0.208514414057\n",
      "  (0, 5818)\t0.208514414057\n",
      "  (0, 5784)\t0.208514414057\n",
      "  (0, 1811)\t0.208514414057\n",
      "  (0, 2796)\t0.208514414057\n",
      "  (0, 2292)\t0.208514414057\n",
      "  (0, 6384)\t0.208514414057\n",
      "  (0, 2018)\t0.208514414057\n",
      "  (0, 4393)\t0.208514414057\n",
      "  (0, 3929)\t0.208514414057\n",
      "  (0, 2636)\t0.208514414057\n",
      "  (0, 1214)\t0.208514414057\n",
      "  (0, 6967)\t0.208514414057\n",
      "  (0, 3023)\t0.208514414057\n",
      "  (0, 4533)\t0.417028828114\n",
      "  (0, 3513)\t0.208514414057\n",
      "  (0, 700)\t0.208514414057\n",
      "  (0, 1252)\t0.208514414057\n",
      "  (0, 6269)\t0.208514414057\n",
      "  (1, 2911)\t0.229415733871\n",
      "  (1, 1490)\t0.229415733871\n",
      "  (1, 3216)\t0.229415733871\n",
      "  (1, 438)\t0.229415733871\n",
      "  (1, 2898)\t0.229415733871\n",
      "  :\t:\n",
      "  (3106, 4667)\t0.204124145232\n",
      "  (3106, 808)\t0.204124145232\n",
      "  (3106, 4623)\t0.204124145232\n",
      "  (3106, 5543)\t0.204124145232\n",
      "  (3106, 4549)\t0.204124145232\n",
      "  (3106, 1490)\t0.204124145232\n",
      "  (3106, 3216)\t0.204124145232\n",
      "  (3106, 6348)\t0.408248290464\n",
      "  (3106, 700)\t0.204124145232\n",
      "  (3107, 6885)\t0.25\n",
      "  (3107, 3451)\t0.25\n",
      "  (3107, 5213)\t0.25\n",
      "  (3107, 2578)\t0.25\n",
      "  (3107, 5045)\t0.25\n",
      "  (3107, 2440)\t0.25\n",
      "  (3107, 6341)\t0.25\n",
      "  (3107, 5870)\t0.25\n",
      "  (3107, 7247)\t0.25\n",
      "  (3107, 2648)\t0.25\n",
      "  (3107, 4623)\t0.25\n",
      "  (3107, 5543)\t0.25\n",
      "  (3107, 1490)\t0.25\n",
      "  (3107, 3216)\t0.25\n",
      "  (3107, 6348)\t0.25\n",
      "  (3107, 700)\t0.25\n",
      "\n",
      "  (0, 6269)\t0.140598737854\n",
      "  (0, 1252)\t0.284770646394\n",
      "  (0, 700)\t0.0371714528678\n",
      "  (0, 3513)\t0.102144859977\n",
      "  (0, 4533)\t0.289107963028\n",
      "  (0, 3023)\t0.284770646394\n",
      "  (0, 6967)\t0.202981496692\n",
      "  (0, 1214)\t0.157691994994\n",
      "  (0, 2636)\t0.284770646394\n",
      "  (0, 3929)\t0.154553347711\n",
      "  (0, 4393)\t0.270940748649\n",
      "  (0, 2018)\t0.155696763985\n",
      "  (0, 6384)\t0.193558846323\n",
      "  (0, 2292)\t0.270940748649\n",
      "  (0, 2796)\t0.284770646394\n",
      "  (0, 1811)\t0.26112828004\n",
      "  (0, 5784)\t0.182590039022\n",
      "  (0, 5818)\t0.270940748649\n",
      "  (0, 2883)\t0.19240250763\n",
      "  (0, 865)\t0.223656015942\n",
      "  (1, 700)\t0.0415586772822\n",
      "  (1, 4334)\t0.283438932681\n",
      "  (1, 791)\t0.302918994739\n",
      "  (1, 644)\t0.120563005505\n",
      "  (1, 2900)\t0.183905316565\n",
      "  :\t:\n",
      "  (3106, 6103)\t0.240282615294\n",
      "  (3106, 201)\t0.239490796335\n",
      "  (3106, 1)\t0.239228862577\n",
      "  (3106, 2723)\t0.240282615294\n",
      "  (3106, 4739)\t0.240548586577\n",
      "  (3106, 1561)\t0.239490796335\n",
      "  (3106, 923)\t0.239753727938\n",
      "  (3106, 2757)\t0.236411350466\n",
      "  (3106, 805)\t0.241622841139\n",
      "  (3107, 700)\t0.0510242786791\n",
      "  (3107, 6348)\t0.101596373289\n",
      "  (3107, 3216)\t0.0747002093216\n",
      "  (3107, 1490)\t0.0737270071512\n",
      "  (3107, 5543)\t0.11784757518\n",
      "  (3107, 4623)\t0.125594240381\n",
      "  (3107, 2648)\t0.148153972859\n",
      "  (3107, 7247)\t0.194032851693\n",
      "  (3107, 5870)\t0.320476066967\n",
      "  (3107, 6341)\t0.236585616232\n",
      "  (3107, 2440)\t0.358443942968\n",
      "  (3107, 5045)\t0.347996327973\n",
      "  (3107, 2578)\t0.347996327973\n",
      "  (3107, 5213)\t0.347996327973\n",
      "  (3107, 3451)\t0.339460004967\n",
      "  (3107, 6885)\t0.347996327973\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf_matrix)\n",
    "print()\n",
    "print(tfidf_matrix)\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tokens(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # sacar numeros, puntuaciones, etc.\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swiftkey',\n",
       " 'apple',\n",
       " 'oh',\n",
       " 'in',\n",
       " 'wish',\n",
       " 'you',\n",
       " 'guys',\n",
       " 'would',\n",
       " 'port',\n",
       " 'hebrew',\n",
       " 'from',\n",
       " 'the',\n",
       " 'android',\n",
       " 'version',\n",
       " 'already',\n",
       " 'i',\n",
       " 'have',\n",
       " 'swapping',\n",
       " 'abck',\n",
       " 'and',\n",
       " 'forth']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens(text[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se transforma todas tweets a valores numéricos (1,0)\n",
    "tweet2index = {}\n",
    "for i, tweet in enumerate(list(set([x for x in text]))):\n",
    "    tweet2index[tweet] = i\n",
    "    \n",
    "y = np.array([tweet2index[x] for x in text])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtener la matriz TF-IDF de los tweets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_1 = TfidfVectorizer(tokenizer=clean_tokens, stop_words='english').fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 7197)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(clf, X, y):\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"%s accuracy: %0.2f (+/- %0.2f)\" % \\\n",
    "          (str(clf.__class__).split('.')[-1].replace('>','').replace(\"'\",''), \n",
    "          scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_models(X, y):\n",
    "    run_model(LinearSVC(), X, y)\n",
    "    run_model(SGDClassifier(), X, y)\n",
    "    run_model(Perceptron(), X, y)\n",
    "    run_model(PassiveAggressiveClassifier(), X, y)\n",
    "    run_model(BernoulliNB(), X, y)\n",
    "    run_model(MultinomialNB(), X, y)\n",
    "    run_model(KNeighborsClassifier(), X, y)\n",
    "    run_model(NearestCentroid(), X, y)\n",
    "    run_model(RandomForestClassifier(n_estimators=100, max_depth=10), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3108, 7197) (3108,)\n"
     ]
    }
   ],
   "source": [
    "print(X_1.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy: 0.80 (+/- 0.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier accuracy: 0.80 (+/- 0.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron accuracy: 0.78 (+/- 0.73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier accuracy: 0.80 (+/- 0.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy: 0.55 (+/- 0.56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy: 0.60 (+/- 0.62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier accuracy: 0.77 (+/- 0.74)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NearestCentroid accuracy: 0.81 (+/- 0.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier accuracy: 0.75 (+/- 0.72)\n"
     ]
    }
   ],
   "source": [
    "run_models(X_1, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando Word Vectors de Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f75372061c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspacy_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mspacy_vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "m=6\n",
    "spacy_vectors = np.identity(m)\n",
    "spacy_vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer = 3\n",
    "\n",
    "theta1 = np.random.rand(hidden_layer,m)\n",
    "theta2 = np.random.rand(m,hidden_layer)\n",
    "\n",
    "print(theta1)\n",
    "print(theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def softmax(H):\n",
    "    sumatoria = sum([math.exp(w) for w in H])\n",
    "    return [math.exp(w)/sumatoria for w in H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(X,theta1,theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1=X\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = sigmoid(z2) #funcion activacion\n",
    "    z3 = a2 * theta2.T\n",
    "    h = sigmoid(z3) #funcion activacion\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward2(X,theta1,theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1=X\n",
    "    a2 = a1 * theta1.T\n",
    "    h = a2 * theta2.T\n",
    "    \n",
    "    return a1,a2, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropagation(thetha1,theta2,X,y):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    a1, z2, a2, z3, h = forward(theta1,theta2,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropagation2(theta1,theta2,X,y):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    a1,a2,h = forward2(X,theta1,theta2)\n",
    "    \n",
    "    delta1 = np.zeros(theta1.shape)  \n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    \n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]\n",
    "        a2t = a2[t,:]\n",
    "        ht = h[t,:]\n",
    "        yt = y[t,:]\n",
    "        \n",
    "        d3t = ht - yt #(1,6)\n",
    "        \n",
    "        d2t = (theta2.T * d3t.T).T #(1,3)\n",
    "        \n",
    "        delta1 = delta1 + d2t.T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    grad1 = delta1\n",
    "    grad2 = delta2\n",
    "    \n",
    "    return grad1,grad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_ = spacy_vectors[3]\n",
    "y_ = spacy_vectors[4]\n",
    "x_ = np.matrix(x_)\n",
    "\n",
    "\n",
    "a1,a2, h = forward2(x_,theta1,theta2)\n",
    "h\n",
    "theta3,theta4 = backpropagation2(theta1,theta2,x_,y_)\n",
    "a1,a2, h = forward2(x_,theta3,theta4)\n",
    "#np.array(h)\n",
    "softmax(np.array(h)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
