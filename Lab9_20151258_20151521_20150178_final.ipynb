{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para este laboratorio, hemos decidido usar un dataset con los tweets que realizaron las personas frente a Apple</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alulab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del archivo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Apple-Twitter-Sentiment-DFE.csv\", header=0,encoding = 'utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>623497694</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 2:57</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Fri Dec 05 19:40:17 +0000 2014</td>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#iPhone5s is the best mobile that I have had. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>623497400</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 16:17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Fri Dec 05 05:59:19 +0000 2014</td>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@apple #YosemiteProblems Erases my saved pass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>623496617</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 0:42</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Thu Dec 04 02:20:40 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Win a #New @Apple @iPad Mini 3 with an @iTune...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>623495564</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 3:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>Tue Dec 02 00:45:03 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#AAPL:Here's why Apple dropped...http://t.co/q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>623496395</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 21:47</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Wed Dec 03 17:41:00 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @thehill: .@Apple CEO @tim_cook visits @Whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "2164  623497694    False   finalized                   3     12/12/14 2:57   \n",
       "1876  623497400    False   finalized                   3    12/12/14 16:17   \n",
       "1098  623496617    False   finalized                   3     12/12/14 0:42   \n",
       "51    623495564    False   finalized                   3     12/12/14 3:38   \n",
       "882   623496395    False   finalized                   3    12/12/14 21:47   \n",
       "\n",
       "     sentiment  sentiment:confidence                            date  \\\n",
       "2164         5                1.0000  Fri Dec 05 19:40:17 +0000 2014   \n",
       "1876         1                1.0000  Fri Dec 05 05:59:19 +0000 2014   \n",
       "1098         3                1.0000  Thu Dec 04 02:20:40 +0000 2014   \n",
       "51           1                0.6656  Tue Dec 02 00:45:03 +0000 2014   \n",
       "882          3                1.0000  Wed Dec 03 17:41:00 +0000 2014   \n",
       "\n",
       "                id            query sentiment_gold  \\\n",
       "2164  5.410000e+17  #AAPL OR @Apple            NaN   \n",
       "1876  5.410000e+17  #AAPL OR @Apple            NaN   \n",
       "1098  5.400000e+17  #AAPL OR @Apple            NaN   \n",
       "51    5.400000e+17  #AAPL OR @Apple            NaN   \n",
       "882   5.400000e+17  #AAPL OR @Apple            NaN   \n",
       "\n",
       "                                                   text  \n",
       "2164  #iPhone5s is the best mobile that I have had. ...  \n",
       "1876  @apple #YosemiteProblems Erases my saved pass ...  \n",
       "1098  #Win a #New @Apple @iPad Mini 3 with an @iTune...  \n",
       "51    #AAPL:Here's why Apple dropped...http://t.co/q...  \n",
       "882   RT @thehill: .@Apple CEO @tim_cook visits @Whi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que no aportan informacion en cuanto al sentimiento dentro del texto. Estas columnas son las fechas, identificadores y estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_golden</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why @Apple Should Ditch TomTom and License Map...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.@Apple heads to trial over digital music clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How an SVN connection led to safer conditions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Terrible service at @Apple store in Bethesda, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TeamCavuto: Protesters stage #DieIn protes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _golden  _trusted_judgments sentiment  sentiment:confidence  \\\n",
       "2911    False                   4         3                0.7364   \n",
       "245     False                   4         3                0.7263   \n",
       "1280    False                   6         5                0.5126   \n",
       "2560    False                   4         1                0.7450   \n",
       "3442    False                   3         3                0.6841   \n",
       "\n",
       "     sentiment_gold                                               text  \n",
       "2911            NaN  Why @Apple Should Ditch TomTom and License Map...  \n",
       "245             NaN  .@Apple heads to trial over digital music clai...  \n",
       "1280            NaN  How an SVN connection led to safer conditions ...  \n",
       "2560            NaN  Terrible service at @Apple store in Bethesda, ...  \n",
       "3442            NaN  RT @TeamCavuto: Protesters stage #DieIn protes...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop([\"_unit_id\",\"_unit_state\",\"date\",\"id\",\"query\",\"_last_judgment_at\"],axis=1)\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos la columna \"sentiment\" que es el dato final que queremos lograr. Además dividimos los datos de forma que el 80% de los datos servirá para entrenar y el 20% restante servirá para probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df2.drop(['sentiment'],axis=1)\n",
    "y_all = df2['sentiment']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_test = 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3060    RT @schreier: It makes you smarter.  Elevate i...\n",
      "1900    @Nale When do you think #parable will be acces...\n",
      "743     Technical Observation of the Day: Tested the 2...\n",
      "3808    APPLE - Fibonacci Technicals Levels - Intraday...\n",
      "1275    What the hell is this @apple @WhatsApp #glitch...\n",
      "3710    Apple to Open New Research Site in Japan $AAPL...\n",
      "829     @jakeflem @Apple take it in. that's a faulty g...\n",
      "3161    Tryng to get back on snapchat but the App Stor...\n",
      "2074    And how about kids?  Do parents need to monito...\n",
      "3481    I seriously f-ing HATE this new version of @Ap...\n",
      "611     Hey @apple could you make an iPhone charger th...\n",
      "2094    #AAPL:Google (GOOGL) Stock Downgraded Today at...\n",
      "2104    .@Apple CEO's name to grace Alabama antidiscri...\n",
      "2395    @jimmymujaj @Apple it works again fucker, not ...\n",
      "1753    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "3041    RT @mydigitalcoco: .@McDonalds Shares a Slice ...\n",
      "3857           why isnt group facetime a thing @apple wtf\n",
      "2178    RT @shannonmmiller: Love the @Apple is support...\n",
      "2697    iPhone 6 Shipping Times Drop to 3-5 Days $AAPL...\n",
      "2966    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "3609    @VentureBeat @obrien .@Apple First to own 2600...\n",
      "2299    got some stuff @apple store &amp; @macys for m...\n",
      "952     RT @evilhag_: why isn't there a dreidel emoji ...\n",
      "1530    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "375     RT @unstanningzarry: my phone keeps fucking fr...\n",
      "2109    For this problem, we can blame anybody we like...\n",
      "584     L.A. School District Officially Ends $1.3 Bill...\n",
      "599     AAPL 'buy' reiterated,  target raised to $130 ...\n",
      "357     @apple make SD cards so we can add memory to o...\n",
      "2526    @wearsy on apple you seem to need a us bank ca...\n",
      "                              ...                        \n",
      "1204    Well thanks @apple for losing over 5000 of my ...\n",
      "956     Dear @Amazon, if @Apple could do it, you can t...\n",
      "1190                     I'm happy now, thnx fags. @apple\n",
      "638     #PeterHewer @Apple iPhone 6 claimed to copy a ...\n",
      "1318    Is Apple The Most Important Stock On Earth?  h...\n",
      "2919    @stevewoz @apple apple stock has doubled since...\n",
      "2896    Could #Apple Inc. Sell 24 Million #AppleWatche...\n",
      "3770    Our new @Technogym treadmills getting assemble...\n",
      "817     Steve Job's Deposition in #iPod Lawsuit Could ...\n",
      "3800    Please, @Apple, don't go the way @Facebook has...\n",
      "3841    RT @iLoveMyMom98: I've tried turning it off an...\n",
      "1502    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "1014    @apple @verizon where the fuck is my phone it ...\n",
      "3575    my iphone6 plus is impossible to hold without ...\n",
      "3815    Zoonova What-If analysis #AAPL #LNKD #FB #GOOG...\n",
      "689     Great FCP X update from @apple today. That wil...\n",
      "1456    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "630     #AAPL #iOS8 RT @BenedictEvans Browser share ht...\n",
      "2890    @Apple When will you follow through &amp; equi...\n",
      "3276    Apple Inc. vs Google Inc: The Battle Of The Te...\n",
      "271     Got A New Phone. @Apple \\r\\n#Iphone6Plus http:...\n",
      "3853    So @Apple just gave me a huge middle finger to...\n",
      "2587    @itsashleyperez @Apple This is an obsession of...\n",
      "1293    RT @SVNetwork: How an SVN connection led to sa...\n",
      "2076    How hip is @TWDanceCenter @Apple Store in Boyl...\n",
      "1064     @sextsatan @Applebees @Apple APPLEBEES FAVED OMG\n",
      "685     RT @FaZeNikan: yea let me just pay 600 dollars...\n",
      "3453     Oh @espn your live streaming on @apple tv blows.\n",
      "1004    You should be able to leave FaceTime video mes...\n",
      "1041    #AAPL:DexCom CEO Terry Gregg Explains 50% YTD ...\n",
      "Name: text, Length: 3886, dtype: object\n",
      "@Nale When do you think #parable will be accessible in France @Apple #AppStore\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "titles =np.array(X_train[\"text\"])\n",
    "print(X_train[\"text\"])\n",
    "print(titles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RT @schreier: It makes you smarter.  Elevate is @apple app of the year!  Congratulations @jessepickard and team.  http://t.co/r0cgmthoCC',\n",
       "       '@Nale When do you think #parable will be accessible in France @Apple #AppStore',\n",
       "       'Technical Observation of the Day: Tested the 20 DMA on Apple $AAPL #aapl\\r\\nhttp://t.co/6EJ6Mbv44f',\n",
       "       ..., 'Oh @espn your live streaming on @apple tv blows.',\n",
       "       'You should be able to leave FaceTime video messages @apple',\n",
       "       '#AAPL:DexCom CEO Terry Gregg Explains 50% YTD Stock Leap, Plans for 2015...http://t.co/bPYVaRmQkP'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \" \".join(titles) \n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminación de URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RT @schreier: It makes you smarter.  Elevate is @apple app of the year!  Congratulations @jessepickard and team.  ',\n",
       "       '@Nale When do you think #parable will be accessible in France @Apple #AppStore',\n",
       "       'Technical Observation of the Day: Tested the 20 DMA on Apple $AAPL #aapl\\r\\n',\n",
       "       ..., 'Oh @espn your live streaming on @apple tv blows.',\n",
       "       'You should be able to leave FaceTime video messages @apple',\n",
       "       '#AAPL:DexCom CEO Terry Gregg Explains 50% YTD Stock Leap, Plans for 2015...'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for i in range(len(titles)):\n",
    "    #URLs_dict = Counter( re.findall(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\",i) )\n",
    "    #URLs = list(URLs_dict.keys())\n",
    "    titles[i] = re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\",\"\", titles[i])\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen todas las siglas presentes en los textos, ya sean un conjunto de 2 o más letras mayúsculas o separadas \n",
    "por punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "my_dict = Counter( re.findall(r\"[A-Z][A-Z]+\",text) )\n",
    "siglas = list(my_dict.keys())\n",
    "my_dict2 = Counter(re.findall(r\"([A-Z]\\.([A-Z]\\.)+)\",text))\n",
    "siglas2 = list(my_dict2.keys())\n",
    "\n",
    "sig =[]\n",
    "for i in siglas2:\n",
    "    sig.append(i[0])\n",
    "siglas = sig + siglas\n",
    "#siglas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como todos los tweets son de idioma inglés se puede quitar las palabras que no aportan (stopwords) y se puede aplicar lemmatization y stem, se intentan conservar las mayúsculas, pues, en un tweet, se usan las mayúsculas para remarcar una idea, normalmente expresa incomodidad u odio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/alulab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords_eng = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords_eng)\n",
    "#stopwords_MAY_eng = list((\" \".join([token.upper() for token in stopwords_eng])).split())\n",
    "#stopwords_MAY_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(titles)):\n",
    "    titles[i] = \" \".join([token for token in titles[i].split() if (token.lower() not in stopwords_eng)])\n",
    "    #len(text.split()) - len(text2.split())\n",
    "\n",
    "text2 = \" \".join([token for token in titles if (token.lower() not in stopwords_eng)])\n",
    "#titles\n",
    "#text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin stop words: \n",
      "cant tokens:  40378\n",
      "tamanho vocabulario:  11021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('@Apple', 1621),\n",
       " ('@apple', 982),\n",
       " ('RT', 847),\n",
       " ('Apple', 495),\n",
       " ('#aapl', 462),\n",
       " ('#AAPL', 408),\n",
       " ('need', 391),\n",
       " ('-', 373),\n",
       " ('4', 344),\n",
       " ('One', 322)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sin stop words: \")\n",
    "my_dicc_No_StopWords = Counter(text2.split())\n",
    "\n",
    "print(\"cant tokens: \",len(text2.split()))\n",
    "print(\"tamanho vocabulario: \",len(my_dicc_No_StopWords))\n",
    "\n",
    "my_dicc_No_StopWords.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "import copy\n",
    "\n",
    "tweets_st =[]\n",
    "for i in range(len(titles)):\n",
    "    copia1 = copy.deepcopy(titles[i])\n",
    "\n",
    "    spliteado = copia1.split()\n",
    "    tweets_stem_split = []\n",
    "    for i in spliteado:\n",
    "        if(i not in siglas):\n",
    "            tweets_stem_split.append(porter.stem(i))\n",
    "        else:\n",
    "            tweets_stem_split.append(i)\n",
    "    tweets_stem = \" \".join([token for token in tweets_stem_split])\n",
    "    tweets_st.append(tweets_stem)\n",
    "\n",
    "#tweets_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Stem: \")\n",
    "#my_dicc_Stem = Counter(tweets_st.split())\n",
    "\n",
    "#print(\"cant tokens: \",len(tweets_st.split()))\n",
    "#print(\"tamanho vocabulario: \",len(my_dicc_Stem))\n",
    "\n",
    "#my_dicc_Stem.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/alulab/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_lemma_split = []\n",
    "\n",
    "tweets_le =[]\n",
    "for i in range(len(titles)):\n",
    "    copia2 = copy.deepcopy(titles[i])\n",
    "\n",
    "    spliteado2 = copia2.split()\n",
    "    tweets_lemma_split = []\n",
    "    for j in spliteado2:\n",
    "        if(j not in siglas):\n",
    "            tweets_lemma_split.append(wnl.lemmatize(j))\n",
    "        else:\n",
    "            tweets_lemma_split.append(j)\n",
    "    tweets_lemma = \" \".join([token for token in tweets_lemma_split])\n",
    "    tweets_le.append(tweets_lemma)\n",
    "#tweets_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokens(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de la Representación Vectorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(clf, X, y):\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"%s accuracy: %0.2f (+/- %0.2f)\" % \\\n",
    "          (str(clf.__class__).split('.')[-1].replace('>','').replace(\"'\",''), \n",
    "          scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(X, y):\n",
    "    run_model(LinearSVC(), X, y)\n",
    "    run_model(SGDClassifier(), X, y)\n",
    "    run_model(Perceptron(), X, y)\n",
    "    run_model(PassiveAggressiveClassifier(), X, y)\n",
    "    run_model(BernoulliNB(), X, y)\n",
    "    run_model(MultinomialNB(), X, y)\n",
    "    run_model(KNeighborsClassifier(), X, y)\n",
    "    run_model(NearestCentroid(), X, y)\n",
    "    run_model(RandomForestClassifier(n_estimators=100, max_depth=10), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RT @schreier: makes smarter. Elevate @apple app year! Congratulations @jessepickard team.',\n",
       "       '@Nale think #parable accessible France @Apple #AppStore',\n",
       "       'Technical Observation Day: Tested 20 DMA Apple $AAPL #aapl', ...,\n",
       "       'Oh @espn live streaming @apple tv blows.',\n",
       "       'able leave FaceTime video messages @apple',\n",
       "       '#AAPL:DexCom CEO Terry Gregg Explains 50% YTD Stock Leap, Plans 2015...'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=titles\n",
    "Documentos = copy.deepcopy(text)\n",
    "Documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se transforma el texto en una matriz de tXd, donde se indica si el token t está en el documento d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "txd_matrix = vectorizer.fit_transform(Documentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se transforma la matriz txd para que sea binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3886, 9359)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txd_matrix = CountVectorizer(binary=True,tokenizer=clean_tokens,stop_words='english').fit_transform(Documentos)\n",
    "txd_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy: 0.72 (+/- 0.02)\n",
      "SGDClassifier accuracy: 0.69 (+/- 0.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron accuracy: 0.70 (+/- 0.02)\n",
      "PassiveAggressiveClassifier accuracy: 0.71 (+/- 0.02)\n",
      "BernoulliNB accuracy: 0.71 (+/- 0.04)\n",
      "MultinomialNB accuracy: 0.69 (+/- 0.03)\n",
      "KNeighborsClassifier accuracy: 0.58 (+/- 0.05)\n",
      "NearestCentroid accuracy: 0.42 (+/- 0.03)\n",
      "RandomForestClassifier accuracy: 0.59 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "run_models(txd_matrix, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF VECTORIZER\n",
    "Una matriz de métricas tfidf para cada documento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocumentosTFIDF = copy.deepcopy(text)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos la matriz de solo tf (tf_matrix) y la matriz tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RT @schreier: makes smarter. Elevate @apple app year! Congratulations @jessepickard team.',\n",
       "       '@Nale think #parable accessible France @Apple #AppStore',\n",
       "       'Technical Observation Day: Tested 20 DMA Apple $AAPL #aapl', ...,\n",
       "       'Oh @espn live streaming @apple tv blows.',\n",
       "       'able leave FaceTime video messages @apple',\n",
       "       '#AAPL:DexCom CEO Terry Gregg Explains 50% YTD Stock Leap, Plans 2015...'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix = TfidfVectorizer(use_idf=False).fit_transform(DocumentosTFIDF)\n",
    "tfidf_matrix = TfidfVectorizer().fit_transform(DocumentosTFIDF)\n",
    "DocumentosTFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tf_matrix[3107])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5088)\t0.12735692980872676\n",
      "  (0, 5181)\t0.36799044533947844\n",
      "  (0, 3762)\t0.3060438412530914\n",
      "  (0, 5425)\t0.36799044533947844\n",
      "  (0, 2036)\t0.3331421442690251\n",
      "  (0, 510)\t0.05480663981426052\n",
      "  (0, 498)\t0.2368736886464376\n",
      "  (0, 6642)\t0.2625556875505071\n",
      "  (0, 1395)\t0.3612770916636009\n",
      "  (0, 3314)\t0.3612770916636009\n",
      "  (0, 5847)\t0.3452666802960426\n",
      "  (1, 510)\t0.057209255901394064\n",
      "  (1, 4073)\t0.4498667391248422\n",
      "  (1, 5964)\t0.299660012144332\n",
      "  (1, 4398)\t0.4498667391248422\n",
      "  (1, 265)\t0.4285881534044897\n",
      "  (1, 2476)\t0.4498667391248422\n",
      "  (1, 566)\t0.34073879146604497\n",
      "  (2, 510)\t0.056091404237431156\n",
      "  (2, 5862)\t0.4054112714783809\n",
      "  (2, 4231)\t0.44107647826637125\n",
      "  (2, 1623)\t0.3017364172759388\n",
      "  (2, 5900)\t0.44107647826637125\n",
      "  (2, 79)\t0.31769513421876\n",
      "  (2, 1851)\t0.44107647826637125\n",
      "  :\t:\n",
      "  (3883, 510)\t0.062473287341961\n",
      "  (3883, 6147)\t0.31033836538668\n",
      "  (3883, 2125)\t0.46802410618919943\n",
      "  (3883, 5660)\t0.3797438590500942\n",
      "  (3883, 4252)\t0.3797438590500942\n",
      "  (3883, 3634)\t0.38857796851202236\n",
      "  (3883, 888)\t0.4912606118733389\n",
      "  (3884, 510)\t0.07473145715859922\n",
      "  (3884, 2224)\t0.4495254728735968\n",
      "  (3884, 250)\t0.4333203145311434\n",
      "  (3884, 3550)\t0.49261847815411436\n",
      "  (3884, 6341)\t0.40923093751399814\n",
      "  (3884, 3873)\t0.440945164760757\n",
      "  (3885, 236)\t0.09416639816841636\n",
      "  (3885, 5636)\t0.20624512901237474\n",
      "  (3885, 1154)\t0.223654750312092\n",
      "  (3885, 4541)\t0.26644794253828774\n",
      "  (3885, 91)\t0.22272060517382944\n",
      "  (3885, 154)\t0.28292341869974247\n",
      "  (3885, 2198)\t0.3201555400538871\n",
      "  (3885, 3544)\t0.33184507642083094\n",
      "  (3885, 1750)\t0.3483205525822857\n",
      "  (3885, 5896)\t0.3483205525822857\n",
      "  (3885, 2720)\t0.3483205525822857\n",
      "  (3885, 6681)\t0.3483205525822857\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix)\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['RT', '@schreier:', 'makes', 'smarter.', 'Elevate', '@apple', 'app', 'year!', 'Congratulations', '@jessepickard', 'team.']),\n",
       "       list(['@Nale', 'think', '#parable', 'accessible', 'France', '@Apple', '#AppStore']),\n",
       "       list(['Technical', 'Observation', 'Day:', 'Tested', '20', 'DMA', 'Apple', '$AAPL', '#aapl']),\n",
       "       ...,\n",
       "       list(['Oh', '@espn', 'live', 'streaming', '@apple', 'tv', 'blows.']),\n",
       "       list(['able', 'leave', 'FaceTime', 'video', 'messages', '@apple']),\n",
       "       list(['#AAPL:DexCom', 'CEO', 'Terry', 'Gregg', 'Explains', '50%', 'YTD', 'Stock', 'Leap,', 'Plans', '2015...'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text1=copy.deepcopy(titles)\n",
    "for i in range(len(text1)):\n",
    "    text1[i]=text1[i].split()\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7647)\t0.12283521020352235\n",
      "  (0, 2631)\t0.3622295037978291\n",
      "  (0, 6312)\t0.29503906408404384\n",
      "  (0, 7997)\t0.3547581815085244\n",
      "  (0, 4640)\t0.33285152152337333\n",
      "  (0, 1896)\t0.06760487333180112\n",
      "  (0, 3133)\t0.24600913798982324\n",
      "  (0, 9281)\t0.3178190388150849\n",
      "  (0, 3996)\t0.34828622776070134\n",
      "  (0, 2312)\t0.34828622776070134\n",
      "  (0, 8432)\t0.34828622776070134\n",
      "  (1, 1896)\t0.07068290446602943\n",
      "  (1, 2487)\t0.43439320492224365\n",
      "  (1, 8544)\t0.29389400132160703\n",
      "  (1, 783)\t0.43439320492224365\n",
      "  (1, 2907)\t0.4138465135503538\n",
      "  (1, 5058)\t0.43439320492224365\n",
      "  (1, 178)\t0.4138465135503538\n",
      "  (2, 8442)\t0.3853399275104976\n",
      "  (2, 6741)\t0.4192393998863267\n",
      "  (2, 4243)\t0.3744267349508602\n",
      "  (2, 8474)\t0.4192393998863267\n",
      "  (2, 1597)\t0.34568008724231225\n",
      "  (2, 4471)\t0.4192393998863267\n",
      "  (2, 3149)\t0.14186054853495048\n",
      "  :\t:\n",
      "  (3882, 2159)\t0.3597907290735688\n",
      "  (3883, 1896)\t0.0784690617990763\n",
      "  (3883, 8745)\t0.3137149672845319\n",
      "  (3883, 8240)\t0.37694330789057695\n",
      "  (3883, 6766)\t0.3727742549228566\n",
      "  (3883, 6194)\t0.38634118111790133\n",
      "  (3883, 2140)\t0.4822442923030203\n",
      "  (3883, 3486)\t0.4822442923030203\n",
      "  (3884, 1896)\t0.09454501163620817\n",
      "  (3884, 4830)\t0.44446802785215944\n",
      "  (3884, 2893)\t0.428445187759341\n",
      "  (3884, 6110)\t0.4870762096506582\n",
      "  (3884, 8959)\t0.4185081508015637\n",
      "  (3884, 6418)\t0.44446802785215944\n",
      "  (3885, 8196)\t0.20429165273396765\n",
      "  (3885, 7056)\t0.25299052452954823\n",
      "  (3885, 3753)\t0.21514889913034912\n",
      "  (3885, 4801)\t0.30398552616946845\n",
      "  (3885, 1715)\t0.3150846621162787\n",
      "  (3885, 67)\t0.3307280156218573\n",
      "  (3885, 8470)\t0.3307280156218573\n",
      "  (3885, 5291)\t0.3307280156218573\n",
      "  (3885, 9339)\t0.3307280156218573\n",
      "  (3885, 6105)\t0.3307280156218573\n",
      "  (3885, 1624)\t0.3307280156218573\n"
     ]
    }
   ],
   "source": [
    "#Obtener la matriz TF-IDF de los tweets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_1 = TfidfVectorizer(tokenizer=clean_tokens, stop_words='english').fit_transform(DocumentosTFIDF)\n",
    "print(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3886, 9359) (3886,)\n"
     ]
    }
   ],
   "source": [
    "print(X_1.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy: 0.73 (+/- 0.02)\n",
      "SGDClassifier accuracy: 0.72 (+/- 0.02)\n",
      "Perceptron accuracy: 0.71 (+/- 0.02)\n",
      "PassiveAggressiveClassifier accuracy: 0.72 (+/- 0.02)\n",
      "BernoulliNB accuracy: 0.71 (+/- 0.04)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy: 0.72 (+/- 0.03)\n",
      "KNeighborsClassifier accuracy: 0.67 (+/- 0.04)\n",
      "NearestCentroid accuracy: 0.51 (+/- 0.05)\n",
      "RandomForestClassifier accuracy: 0.59 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "run_models(X_1, y_train)\n",
    "\n",
    "\n",
    "#clf = LinearSVC(random_state = 0)\n",
    "#clf.fit(X_1,y_train)\n",
    "\n",
    "#prueba = [\"a\"] * X_1.shape[1]\n",
    "#prueba[0] = \"I loved this amazing version\"\n",
    "#print(prueba)\n",
    "#X_5 = TfidfVectorizer(tokenizer=clean_tokens, stop_words='english').fit_transform(prueba)\n",
    "\n",
    "#X_5\n",
    "#clf.predict(X_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando Word Vectors de Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RT @schreier: makes smarter. Elevate @apple app year! Congratulations @jessepickard team.',\n",
       "       '@Nale think #parable accessible France @Apple #AppStore',\n",
       "       'Technical Observation Day: Tested 20 DMA Apple $AAPL #aapl', ...,\n",
       "       'Oh @espn live streaming @apple tv blows.',\n",
       "       'able leave FaceTime video messages @apple',\n",
       "       '#AAPL:DexCom CEO Terry Gregg Explains 50% YTD Stock Leap, Plans 2015...'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz --user\n",
    "#!pip install --upgrade pip --user\n",
    "import spacy,gensim\n",
    "Documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import spacy\n",
    "#nlp = spacy.load('en_core_web_lg')\n",
    "#doc = nlp(u'This is a sentence.')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "\n",
    "\n",
    "#model = gensim.models.Word2Vec(text1,size = len(Documentos),window = 20)\n",
    "#print(model)\n",
    "#len(Documentos)\n",
    "#model['preview']\n",
    "#text1\n",
    "#model.train(Documentos,total_examples = len(Documentos))\n",
    "#len(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoresDoc = list()\n",
    "for documento in Documentos:\n",
    "    vectoresDoc.append(nlp(documento).vector)\n",
    "\n",
    "#doc[2]\n",
    "#len(doc[3].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models_spacy(X,y):\n",
    "    run_model(LinearSVC(), X, y)\n",
    "    run_model(SGDClassifier(), X, y)\n",
    "    run_model(Perceptron(), X, y)\n",
    "    run_model(PassiveAggressiveClassifier(), X, y)\n",
    "    run_model(BernoulliNB(), X, y)\n",
    "    #run_model(MultinomialNB(), X, y)\n",
    "    run_model(KNeighborsClassifier(), X, y)\n",
    "    run_model(NearestCentroid(), X, y)\n",
    "    run_model(RandomForestClassifier(n_estimators=100, max_depth=10), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy: 0.73 (+/- 0.03)\n",
      "SGDClassifier accuracy: 0.63 (+/- 0.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron accuracy: 0.69 (+/- 0.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier accuracy: 0.65 (+/- 0.13)\n",
      "BernoulliNB accuracy: 0.57 (+/- 0.06)\n",
      "KNeighborsClassifier accuracy: 0.71 (+/- 0.04)\n",
      "NearestCentroid accuracy: 0.42 (+/- 0.05)\n",
      "RandomForestClassifier accuracy: 0.72 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "run_models_spacy(vectoresDoc,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"from gensim.models import Word2Vec\n",
    "sentences = text1\n",
    "model = Word2Vec(min_count=1,size = 300,window=2)\n",
    "model.build_vocab(sentences)\n",
    "model.train(sentences, total_examples=len(Documentos), epochs=model.epochs)\n",
    "print(model)\n",
    "#len()\n",
    "#titles\n",
    "print(text1)\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
