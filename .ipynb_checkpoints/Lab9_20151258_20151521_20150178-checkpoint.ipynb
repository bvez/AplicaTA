{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para este laboratorio, hemos decidido usar un dataset con los tweets que realizaron las personas frente a Apple</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del archivo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Apple-Twitter-Sentiment-DFE.csv\", header=0,encoding = 'utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>623497301</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 2:36</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Fri Dec 05 00:49:28 +0000 2014</td>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @MissionIR: Is Apple The Most Important Sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>623496292</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 8:43</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Wed Dec 03 15:00:41 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Big Spending by Consumers on Cyber Monday\\r\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>623498300</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/11/14 21:13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6505</td>\n",
       "      <td>Sun Dec 07 21:30:02 +0000 2014</td>\n",
       "      <td>5.420000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trade $AAPL #FREE Nightly Updates are #posted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>623497618</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 13:17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>Fri Dec 05 17:13:59 +0000 2014</td>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barclays raises Apple price target by 17% to $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>623495963</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/11/14 22:12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>Tue Dec 02 19:35:16 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Was pleased to meet a fellow tweep at @apple #...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "1777  623497301    False   finalized                   3     12/12/14 2:36   \n",
       "779   623496292    False   finalized                   3     12/12/14 8:43   \n",
       "2770  623498300    False   finalized                   3    12/11/14 21:13   \n",
       "2088  623497618    False   finalized                   3    12/12/14 13:17   \n",
       "450   623495963    False   finalized                   3    12/11/14 22:12   \n",
       "\n",
       "     sentiment  sentiment:confidence                            date  \\\n",
       "1777         3                1.0000  Fri Dec 05 00:49:28 +0000 2014   \n",
       "779          3                1.0000  Wed Dec 03 15:00:41 +0000 2014   \n",
       "2770         3                0.6505  Sun Dec 07 21:30:02 +0000 2014   \n",
       "2088         3                0.6851  Fri Dec 05 17:13:59 +0000 2014   \n",
       "450          5                0.6650  Tue Dec 02 19:35:16 +0000 2014   \n",
       "\n",
       "                id            query sentiment_gold  \\\n",
       "1777  5.410000e+17  #AAPL OR @Apple            NaN   \n",
       "779   5.400000e+17  #AAPL OR @Apple            NaN   \n",
       "2770  5.420000e+17  #AAPL OR @Apple            NaN   \n",
       "2088  5.410000e+17  #AAPL OR @Apple            NaN   \n",
       "450   5.400000e+17  #AAPL OR @Apple            NaN   \n",
       "\n",
       "                                                   text  \n",
       "1777  RT @MissionIR: Is Apple The Most Important Sto...  \n",
       "779   Big Spending by Consumers on Cyber Monday\\r\\n\\...  \n",
       "2770  Trade $AAPL #FREE Nightly Updates are #posted ...  \n",
       "2088  Barclays raises Apple price target by 17% to $...  \n",
       "450   Was pleased to meet a fellow tweep at @apple #...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que no aportan informacion en cuanto al sentimiento dentro del texto. Estas columnas son las fechas, identificadores y estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_golden</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>For this problem, we can blame anybody we like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>3\\r\\n1</td>\n",
       "      <td>@apple emojis en mac, pleaaaase! :(((</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @OneRepublic: Studio at 45,000 ft.  One out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Protesters stage #DieIn protests in @Apple sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apple Gets Price Target Boost on Back of Stron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _golden  _trusted_judgments sentiment  sentiment:confidence  \\\n",
       "2109    False                   6         3                0.5123   \n",
       "2296     True                  12         1                0.5833   \n",
       "1904    False                   3         3                0.6800   \n",
       "3297    False                   3         3                0.6515   \n",
       "321     False                   3         3                1.0000   \n",
       "\n",
       "     sentiment_gold                                               text  \n",
       "2109            NaN  For this problem, we can blame anybody we like...  \n",
       "2296         3\\r\\n1              @apple emojis en mac, pleaaaase! :(((  \n",
       "1904            NaN  RT @OneRepublic: Studio at 45,000 ft.  One out...  \n",
       "3297            NaN  Protesters stage #DieIn protests in @Apple sto...  \n",
       "321             NaN  Apple Gets Price Target Boost on Back of Stron...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop([\"_unit_id\",\"_unit_state\",\"date\",\"id\",\"query\",\"_last_judgment_at\"],axis=1)\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos la columna \"sentiment\" que es el dato final que queremos lograr. Además dividimos los datos de forma que el 80% de los datos servirá para entrenar y el 20% restante servirá para probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df2.drop(['sentiment'],axis=1)\n",
    "y_all = df2['sentiment']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_test = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3222    Steve Wozniak Says @Apple Starting In Garage I...\n",
      "1009    @pdbogen Yeah, it's not for everyone. I sold m...\n",
      "263     A lack of equal access to technology places st...\n",
      "2638    Enjoying my studio wireless beats. @beatsbydre...\n",
      "609     No at typo changing my words. Get it together ...\n",
      "3198    Few spots left @WWCLondon's 10 Dec event @Appl...\n",
      "592     Also I've had my iPhone 6 for two days and it'...\n",
      "1405    Apple 'deleted' rivals' music from iPods, cour...\n",
      "427     RT @IDSA: Legendary @Apple designer @SusanKare...\n",
      "3873    Apple Is Warming Up To Social Media: Apple is ...\n",
      "2005    @AppleOfficialll @apple I can't say enough abo...\n",
      "1891    Torn between @SamsungMobileUS and @apple for m...\n",
      "2083    Dear @Apple all I want for Xmas is for iOS 8 t...\n",
      "2803    3 Simple Things #Investors Ought to Know Befor...\n",
      "1332    RT @_JuGatti: Wouldn't be a bad idea to bring ...\n",
      "2796    #AAPL:Buzz Stocks: Apple Inc. (AAPL), RadioSha...\n",
      "3170                       @justinbieber @apple get on it\n",
      "38      RT @thehill: Justice Department cites 18th cen...\n",
      "348     CNBCTV:  #iPhone growth peaked? #aapl  http://...\n",
      "612     fuck apple for allowing ppl to access the came...\n",
      "1492    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "2405             @abbey_ivey here ask my friends @ @apple\n",
      "1881    @cynthialanel @twitter silicon valley as a who...\n",
      "1711    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "2126    RT @shannonmmiller: Love the @Apple is support...\n",
      "2603                   dear @Apple get your shit together\n",
      "2264                          Things are happening @apple\n",
      "2591    @stevewoz @Outback Its good to see you doing t...\n",
      "1437    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "2660    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "                              ...                        \n",
      "3724    2015 to be the year of biometrics, wearables, ...\n",
      "2028    @apple awards @RegisCollege_MA with Distinguis...\n",
      "3645    #aapl traders? chart looks weaker than I'd lik...\n",
      "1441    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "1383    It took just one month for the #iPhone6Plus to...\n",
      "1399    RT Different is Normal http://t.co/6cbUmYzRlm ...\n",
      "1401    #Apple: Kantar's Data Points To A Huge Decembe...\n",
      "2726    2) @Apple I've got one question for yall. Who ...\n",
      "1032    my laptop battery went straight from 60% to 3%...\n",
      "3124    BloombergTV:  #Wozniak: What Really Happened i...\n",
      "2729    iPhone 6, 6 Plus Availability And Wait Time Up...\n",
      "1022    Shockingly, iMessage on the desktop is fucked ...\n",
      "537     #Apple Inc. #AAPL News Analysis: Did Apple Inc...\n",
      "719     #Rumors #Surface for @@Apple [#Apple] #iPhone6...\n",
      "453     @UberFacts i can think of 100 reasons not to i...\n",
      "3731    .@Apple and @Amazon refuse to make full federa...\n",
      "2841    Gonna be dreaming about my laptop.. If only @A...\n",
      "546     @Apple sets its own timetable (rather than cha...\n",
      "365                my phone keeps fucking freezing @apple\n",
      "3447    RT @TeamCavuto: Protesters stage #DieIn protes...\n",
      "2091    RT @JPDesloges: Apple to Support a New Franchi...\n",
      "3481    I seriously f-ing HATE this new version of @Ap...\n",
      "3120    CNBCTV:  Citi's #Apple optimism #aapl http://t...\n",
      "1745    Yay @Apple customer support was super nice and...\n",
      "3023    Purchase a $99 @apple TV ($99 Value) simply by...\n",
      "429     @NCRcorporation Silver Merchants Prefer #Bitco...\n",
      "138     RT @donacamp: Brass band at @Apple Store Broad...\n",
      "1048    New HA Blog Post &gt;&gt;&gt; Final #AAPL #Put...\n",
      "2084    @Apple was fighting a 'never ending battle' ag...\n",
      "2602    MY IPAD IS GLITCHING SO BAD AND IT ISNT CHARGI...\n",
      "Name: text, Length: 3108, dtype: object\n",
      "@pdbogen Yeah, it's not for everyone. I sold my soul to @Apple a while ago. Thanks for the link!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "titles =np.array(X_train[\"text\"])\n",
    "print(X_train[\"text\"])\n",
    "print(titles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \" \".join(titles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "txd_matrix = vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 7351)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txd_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2123)\t1\n",
      "  (0, 3669)\t1\n",
      "  (0, 1475)\t2\n",
      "  (0, 3198)\t2\n",
      "  (0, 6083)\t1\n",
      "  (0, 4401)\t1\n",
      "  (0, 1537)\t1\n",
      "  (0, 3494)\t1\n",
      "  (0, 2779)\t1\n",
      "  (0, 3333)\t1\n",
      "  (0, 6056)\t1\n",
      "  (0, 677)\t1\n",
      "  (0, 5644)\t1\n",
      "  (0, 7127)\t1\n",
      "  (0, 6079)\t1\n",
      "  (1, 3934)\t1\n",
      "  (1, 6373)\t1\n",
      "  (1, 6367)\t1\n",
      "  (1, 525)\t1\n",
      "  (1, 7020)\t1\n",
      "  (1, 6464)\t1\n",
      "  (1, 5970)\t1\n",
      "  (1, 4397)\t1\n",
      "  (1, 5935)\t1\n",
      "  (1, 2328)\t1\n",
      "  :\t:\n",
      "  (3106, 900)\t1\n",
      "  (3106, 4469)\t1\n",
      "  (3106, 6542)\t1\n",
      "  (3106, 521)\t1\n",
      "  (3106, 654)\t1\n",
      "  (3106, 6942)\t1\n",
      "  (3106, 3525)\t1\n",
      "  (3106, 4623)\t1\n",
      "  (3106, 1475)\t1\n",
      "  (3106, 3198)\t1\n",
      "  (3106, 3333)\t1\n",
      "  (3106, 677)\t1\n",
      "  (3106, 5644)\t1\n",
      "  (3107, 3503)\t1\n",
      "  (3107, 2854)\t1\n",
      "  (3107, 1361)\t1\n",
      "  (3107, 7144)\t1\n",
      "  (3107, 5927)\t1\n",
      "  (3107, 866)\t1\n",
      "  (3107, 3447)\t1\n",
      "  (3107, 620)\t1\n",
      "  (3107, 4397)\t1\n",
      "  (3107, 3512)\t1\n",
      "  (3107, 3494)\t1\n",
      "  (3107, 677)\t1\n"
     ]
    }
   ],
   "source": [
    "print (txd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "txd_matrix = CountVectorizer(binary=True).fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2123)\t1\n",
      "  (0, 3669)\t1\n",
      "  (0, 1475)\t1\n",
      "  (0, 3198)\t1\n",
      "  (0, 6083)\t1\n",
      "  (0, 4401)\t1\n",
      "  (0, 1537)\t1\n",
      "  (0, 3494)\t1\n",
      "  (0, 2779)\t1\n",
      "  (0, 3333)\t1\n",
      "  (0, 6056)\t1\n",
      "  (0, 677)\t1\n",
      "  (0, 5644)\t1\n",
      "  (0, 7127)\t1\n",
      "  (0, 6079)\t1\n",
      "  (1, 3934)\t1\n",
      "  (1, 6373)\t1\n",
      "  (1, 6367)\t1\n",
      "  (1, 525)\t1\n",
      "  (1, 7020)\t1\n",
      "  (1, 6464)\t1\n",
      "  (1, 5970)\t1\n",
      "  (1, 4397)\t1\n",
      "  (1, 5935)\t1\n",
      "  (1, 2328)\t1\n",
      "  :\t:\n",
      "  (3106, 900)\t1\n",
      "  (3106, 4469)\t1\n",
      "  (3106, 6542)\t1\n",
      "  (3106, 521)\t1\n",
      "  (3106, 654)\t1\n",
      "  (3106, 6942)\t1\n",
      "  (3106, 3525)\t1\n",
      "  (3106, 4623)\t1\n",
      "  (3106, 1475)\t1\n",
      "  (3106, 3198)\t1\n",
      "  (3106, 3333)\t1\n",
      "  (3106, 677)\t1\n",
      "  (3106, 5644)\t1\n",
      "  (3107, 3503)\t1\n",
      "  (3107, 2854)\t1\n",
      "  (3107, 1361)\t1\n",
      "  (3107, 7144)\t1\n",
      "  (3107, 5927)\t1\n",
      "  (3107, 866)\t1\n",
      "  (3107, 3447)\t1\n",
      "  (3107, 620)\t1\n",
      "  (3107, 4397)\t1\n",
      "  (3107, 3512)\t1\n",
      "  (3107, 3494)\t1\n",
      "  (3107, 677)\t1\n"
     ]
    }
   ],
   "source": [
    "print(txd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = TfidfVectorizer(use_idf=False).fit_transform(text)\n",
    "tfidf_matrix = TfidfVectorizer().fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 7351)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2123)\t0.218217890236\n",
      "  (0, 3669)\t0.218217890236\n",
      "  (0, 1475)\t0.436435780472\n",
      "  (0, 3198)\t0.436435780472\n",
      "  (0, 6083)\t0.218217890236\n",
      "  (0, 4401)\t0.218217890236\n",
      "  (0, 1537)\t0.218217890236\n",
      "  (0, 3494)\t0.218217890236\n",
      "  (0, 2779)\t0.218217890236\n",
      "  (0, 3333)\t0.218217890236\n",
      "  (0, 6056)\t0.218217890236\n",
      "  (0, 677)\t0.218217890236\n",
      "  (0, 5644)\t0.218217890236\n",
      "  (0, 7127)\t0.218217890236\n",
      "  (0, 6079)\t0.218217890236\n",
      "  (1, 3934)\t0.229415733871\n",
      "  (1, 6373)\t0.229415733871\n",
      "  (1, 6367)\t0.229415733871\n",
      "  (1, 525)\t0.229415733871\n",
      "  (1, 7020)\t0.229415733871\n",
      "  (1, 6464)\t0.229415733871\n",
      "  (1, 5970)\t0.229415733871\n",
      "  (1, 4397)\t0.229415733871\n",
      "  (1, 5935)\t0.229415733871\n",
      "  (1, 2328)\t0.229415733871\n",
      "  :\t:\n",
      "  (3106, 900)\t0.22360679775\n",
      "  (3106, 4469)\t0.22360679775\n",
      "  (3106, 6542)\t0.22360679775\n",
      "  (3106, 521)\t0.22360679775\n",
      "  (3106, 654)\t0.22360679775\n",
      "  (3106, 6942)\t0.22360679775\n",
      "  (3106, 3525)\t0.22360679775\n",
      "  (3106, 4623)\t0.22360679775\n",
      "  (3106, 1475)\t0.22360679775\n",
      "  (3106, 3198)\t0.22360679775\n",
      "  (3106, 3333)\t0.22360679775\n",
      "  (3106, 677)\t0.22360679775\n",
      "  (3106, 5644)\t0.22360679775\n",
      "  (3107, 3503)\t0.288675134595\n",
      "  (3107, 2854)\t0.288675134595\n",
      "  (3107, 1361)\t0.288675134595\n",
      "  (3107, 7144)\t0.288675134595\n",
      "  (3107, 5927)\t0.288675134595\n",
      "  (3107, 866)\t0.288675134595\n",
      "  (3107, 3447)\t0.288675134595\n",
      "  (3107, 620)\t0.288675134595\n",
      "  (3107, 4397)\t0.288675134595\n",
      "  (3107, 3512)\t0.288675134595\n",
      "  (3107, 3494)\t0.288675134595\n",
      "  (3107, 677)\t0.288675134595\n",
      "\n",
      "  (0, 6079)\t0.214096699844\n",
      "  (0, 7127)\t0.276131681956\n",
      "  (0, 5644)\t0.256639657848\n",
      "  (0, 677)\t0.0470888689476\n",
      "  (0, 6056)\t0.342563938898\n",
      "  (0, 3333)\t0.118856024916\n",
      "  (0, 2779)\t0.282779486517\n",
      "  (0, 3494)\t0.118218299927\n",
      "  (0, 1537)\t0.342563938898\n",
      "  (0, 4401)\t0.300265317902\n",
      "  (0, 6083)\t0.282779486517\n",
      "  (0, 3198)\t0.138165888316\n",
      "  (0, 1475)\t0.136312039941\n",
      "  (0, 3669)\t0.360049770283\n",
      "  (0, 2123)\t0.360049770283\n",
      "  (1, 677)\t0.0479787403513\n",
      "  (1, 4852)\t0.366853883477\n",
      "  (1, 7222)\t0.28134993614\n",
      "  (1, 3512)\t0.130968545513\n",
      "  (1, 4543)\t0.186947004428\n",
      "  (1, 2637)\t0.276860346113\n",
      "  (1, 2328)\t0.300764216085\n",
      "  (1, 5935)\t0.300764216085\n",
      "  (1, 4397)\t0.142764034991\n",
      "  (1, 5970)\t0.349037610065\n",
      "  :\t:\n",
      "  (3106, 6942)\t0.17352684226\n",
      "  (3106, 654)\t0.212436825835\n",
      "  (3106, 521)\t0.225942847108\n",
      "  (3106, 6542)\t0.215376683498\n",
      "  (3106, 4469)\t0.230268854685\n",
      "  (3106, 900)\t0.281185524279\n",
      "  (3106, 2161)\t0.260631612373\n",
      "  (3106, 1692)\t0.255727189482\n",
      "  (3106, 2534)\t0.291751687889\n",
      "  (3106, 2243)\t0.281185524279\n",
      "  (3106, 2987)\t0.306643859076\n",
      "  (3106, 1388)\t0.306643859076\n",
      "  (3106, 4661)\t0.306643859076\n",
      "  (3107, 677)\t0.0597479818935\n",
      "  (3107, 3494)\t0.1499994585\n",
      "  (3107, 3512)\t0.16309528405\n",
      "  (3107, 4397)\t0.177784220995\n",
      "  (3107, 620)\t0.173301801805\n",
      "  (3107, 3447)\t0.264695482852\n",
      "  (3107, 866)\t0.343058708971\n",
      "  (3107, 5927)\t0.231454170984\n",
      "  (3107, 7144)\t0.323200900247\n",
      "  (3107, 1361)\t0.418915285233\n",
      "  (3107, 2854)\t0.43465694709\n",
      "  (3107, 3503)\t0.418915285233\n"
     ]
    }
   ],
   "source": [
    "print(tf_matrix)\n",
    "print()\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bd7fd57ffd36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokens(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # sacar numeros, puntuaciones, etc.\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens(text[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se transforma todas tweets a valores numéricos (1,0)\n",
    "tweet2index = {}\n",
    "for i, tweet in enumerate(list(set([x for x in text]))):\n",
    "    tweet2index[tweet] = i\n",
    "    \n",
    "y = np.array([tweet2index[x] for x in text])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener la matriz TF-IDF de los tweets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_1 = TfidfVectorizer(tokenizer=clean_tokens, stop_words='english').fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(clf, X, y):\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"%s accuracy: %0.2f (+/- %0.2f)\" % \\\n",
    "          (str(clf.__class__).split('.')[-1].replace('>','').replace(\"'\",''), \n",
    "          scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(X, y):\n",
    "    run_model(SGDClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_1.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_models(X_1, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
