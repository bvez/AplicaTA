{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para este laboratorio, hemos decidido usar un dataset con los tweets que realizaron las personas frente a Apple</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura del archivo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Apple-Twitter-Sentiment-DFE.csv\", header=0,encoding = 'utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>623496858</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 17:53</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Thu Dec 04 17:28:21 +0000 2014</td>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An OSX update just bricked my MacBook Pro!. @a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>623495634</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 16:19</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Tue Dec 02 03:58:50 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Well played @apple http://t.co/mGbsxyiA69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>623496766</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 12:15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Thu Dec 04 14:43:49 +0000 2014</td>\n",
       "      <td>5.410000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Samsung is way better than @Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>623498725</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/11/14 21:03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>Mon Dec 08 21:46:04 +0000 2014</td>\n",
       "      <td>5.420000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Happy Monday! My camera on my fancy @Apple #iP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>623495568</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>4</td>\n",
       "      <td>12/12/14 22:25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>Tue Dec 02 00:51:10 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Final #AAPL #PutCallRatios for Monday, Decembe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "1334  623496858    False   finalized                   3    12/12/14 17:53   \n",
       "121   623495634    False   finalized                   3    12/12/14 16:19   \n",
       "1242  623496766    False   finalized                   3    12/12/14 12:15   \n",
       "3195  623498725    False   finalized                   3    12/11/14 21:03   \n",
       "55    623495568    False   finalized                   4    12/12/14 22:25   \n",
       "\n",
       "     sentiment  sentiment:confidence                            date  \\\n",
       "1334         1                1.0000  Thu Dec 04 17:28:21 +0000 2014   \n",
       "121          5                1.0000  Tue Dec 02 03:58:50 +0000 2014   \n",
       "1242         1                1.0000  Thu Dec 04 14:43:49 +0000 2014   \n",
       "3195         1                0.6722  Mon Dec 08 21:46:04 +0000 2014   \n",
       "55           3                0.7320  Tue Dec 02 00:51:10 +0000 2014   \n",
       "\n",
       "                id            query sentiment_gold  \\\n",
       "1334  5.410000e+17  #AAPL OR @Apple            NaN   \n",
       "121   5.400000e+17  #AAPL OR @Apple            NaN   \n",
       "1242  5.410000e+17  #AAPL OR @Apple            NaN   \n",
       "3195  5.420000e+17  #AAPL OR @Apple            NaN   \n",
       "55    5.400000e+17  #AAPL OR @Apple            NaN   \n",
       "\n",
       "                                                   text  \n",
       "1334  An OSX update just bricked my MacBook Pro!. @a...  \n",
       "121           Well played @apple http://t.co/mGbsxyiA69  \n",
       "1242                 @Samsung is way better than @Apple  \n",
       "3195  Happy Monday! My camera on my fancy @Apple #iP...  \n",
       "55    Final #AAPL #PutCallRatios for Monday, Decembe...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas que no aportan informacion en cuanto al sentimiento dentro del texto. Estas columnas son las fechas, identificadores y estados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_golden</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yall some hoes BRUH @apple http://t.co/BBVtlFzzpK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did @apple delete #music from sites other than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MasterCard Teams Up With Gwen Stefani to Promo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey @netflix how come every Saturday movie nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#AAPL:Samsung asks appeals court to throw out ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      _golden  _trusted_judgments sentiment  sentiment:confidence  \\\n",
       "2745    False                   3         1                0.6804   \n",
       "1726    False                   3         3                0.6774   \n",
       "3077    False                   3         3                1.0000   \n",
       "2626    False                   6         1                0.6565   \n",
       "1614    False                   3         3                0.7079   \n",
       "\n",
       "     sentiment_gold                                               text  \n",
       "2745            NaN  Yall some hoes BRUH @apple http://t.co/BBVtlFzzpK  \n",
       "1726            NaN  Did @apple delete #music from sites other than...  \n",
       "3077            NaN  MasterCard Teams Up With Gwen Stefani to Promo...  \n",
       "2626            NaN  Hey @netflix how come every Saturday movie nig...  \n",
       "1614            NaN  #AAPL:Samsung asks appeals court to throw out ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop([\"_unit_id\",\"_unit_state\",\"date\",\"id\",\"query\",\"_last_judgment_at\"],axis=1)\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos la columna \"sentiment\" que es el dato final que queremos lograr. Además dividimos los datos de forma que el 80% de los datos servirá para entrenar y el 20% restante servirá para probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df2.drop(['sentiment'],axis=1)\n",
    "y_all = df2['sentiment']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_test = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3310    RT @TeamCavuto: Protesters stage #DieIn protes...\n",
      "2764    Apple: Market Maker Price Range Forecast Updat...\n",
      "1070    How Competition Between Wireless Carriers Bene...\n",
      "2085    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "95      #whoknew Why isn't @Apple on Twitter? http://t...\n",
      "2824          @CarlaBarlaCakes @MoBiggaa @Apple snapchat?\n",
      "3342    RT @TeamCavuto: Protesters stage #DieIn protes...\n",
      "3668    @Apple seems to be nailing it with @applepay, ...\n",
      "3211                        #AAPL deep in the money Calls\n",
      "3161    Tryng to get back on snapchat but the App Stor...\n",
      "1805    @apple official I have 2 appletv's constantly ...\n",
      "642     Love my @apple #macbookpro. Best ever http://t...\n",
      "2306    Just trying to buy a charger at @apple! #prote...\n",
      "2468    RT @Vito_sfam: Hey @apple, the battery of my i...\n",
      "1773    'Could Falling Oil Prices Spark A Financial Cr...\n",
      "3298    For the past week my phone stay freezing &amp;...\n",
      "3769    Apple Releases iOS 8.1.2 With Fix for Disappea...\n",
      "2405             @abbey_ivey here ask my friends @ @apple\n",
      "2790    @sprint refuses to unlock my out of contract i...\n",
      "822     Did anyone update their Yosemite? My macbook i...\n",
      "3641    Translate Your App! Success story from TAUS me...\n",
      "346     http://t.co/7iyWkaiMss @apple Early Adoption I...\n",
      "3265    Apple Inc. is Catching up on iPhone 6 Supply, ...\n",
      "3760    iPod Lawsuit Loses Last Plaintiff as Judge Dis...\n",
      "681                       @FaZeNikan @Apple Wrong @ Homie\n",
      "3455    RT @TeamCavuto: Protesters stage #DieIn protes...\n",
      "3585    @Apple Is Already Building Its Next Massive Bu...\n",
      "2457    Tax Reform: What to Expect From the New Congre...\n",
      "417     @Google #Chromecast Leapfrogs @Apple #TV as th...\n",
      "250     RT @laurrynk: Dear @apple replace my phone my ...\n",
      "                              ...                        \n",
      "3215    I don't know what you're trying to do @apple b...\n",
      "70      Then how the hell did I take this screenshot? ...\n",
      "1655    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "2913    @Apple [#Apple]'s #iPhone6 China Unicom Lead. ...\n",
      "2154    Plaintiff withdrawn in iPod antitrust lawsuit ...\n",
      "2214    Foreign Currency Exchange May Be A Headwind Fo...\n",
      "3438    RT @TeamCavuto: Protesters stage #DieIn protes...\n",
      "2990    Takes more than #marketing to convert shoppers...\n",
      "630     #AAPL #iOS8 RT @BenedictEvans Browser share ht...\n",
      "3673    APPLE - Fibonacci Technicals Levels - Intraday...\n",
      "3523                @Tyniaaaa_  FUCK @JColeNC  and @apple\n",
      "448     @LittleWordBites @Apple @TommyHilfiger Sounds ...\n",
      "3556    RT @Jus_Trippy: i need new emojis , preferably...\n",
      "2272    #iPhone6c release date, #rumours and #leaked i...\n",
      "2052    Resisting a Bite of the #Holiday @Apple - http...\n",
      "3252    Best Buy Cuts Apple Inc. iPad Prices to Boost ...\n",
      "968     RT @JPDesloges: The iPhone 6 Plus Will Be Huge...\n",
      "2434    a split in The Valley on user data? @Apple say...\n",
      "1580    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "433     @SamJam Agreed--have to give props to @Apple f...\n",
      "2523    @Apple @iCloud Family in-app purchase approval...\n",
      "1849    RT @KaminaBlue: Get three way FaceTimeing. Im ...\n",
      "2660    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "837     What's at the core of @Apple's new #iOS7? Exce...\n",
      "3682    @Apple building massive new #R&amp;D center in...\n",
      "276     #CNBC will make you poor  #CL just got slammed...\n",
      "2183                 @Apple honey crisp apple for the win\n",
      "1498    RT @OneRepublic: Studio at 45,000 ft.  One out...\n",
      "1265    Tim #Cook's $100 Billion 'Mistake' #aapl http:...\n",
      "765     Go Apple! Looks like a little squeeze again :)...\n",
      "Name: text, Length: 3108, dtype: object\n",
      "Apple: Market Maker Price Range Forecast Update $AAPL #aapl\r\n",
      "http://t.co/pxOoOAKuy8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "titles =np.array(X_train[\"text\"])\n",
    "print(X_train[\"text\"])\n",
    "print(titles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \" \".join(titles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RT @TeamCavuto: Protesters stage #DieIn protests in @Apple store in NYC... Is it me, or is this anger misplaced? RETWEET if you agree.',\n",
       "       'Apple: Market Maker Price Range Forecast Update $AAPL #aapl\\r\\nhttp://t.co/pxOoOAKuy8',\n",
       "       'How Competition Between Wireless Carriers Benefits Apple, Inc. http://t.co/9wBMngm62w #AAPL',\n",
       "       ...,\n",
       "       'RT @OneRepublic: Studio at 45,000 ft.  One outlet,  4 computers.  @Apple we need the batteries of the future NoW!!!! http://t.co/astp9x6KET',\n",
       "       \"Tim #Cook's $100 Billion 'Mistake' #aapl http://t.co/BkWq9RyDeb http://t.co/s77JNrg1n4\",\n",
       "       'Go Apple! Looks like a little squeeze again :) #aapl $stocks'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=titles\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "txd_matrix = vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 7389)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txd_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (txd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "txd_matrix = CountVectorizer(binary=True).fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(txd_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = TfidfVectorizer(use_idf=False).fit_transform(text)\n",
    "tfidf_matrix = TfidfVectorizer().fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 7389)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tf_matrix)\n",
    "#print()\n",
    "#print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokens(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # sacar numeros, puntuaciones, etc.\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'why', 'is', \"n't\", 'there', 'an', 'otter', 'emoji']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens(text[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se transforma todas tweets a valores numéricos (1,0)\n",
    "tweet2index = {}\n",
    "for i, tweet in enumerate(list(set([x for x in text]))):\n",
    "    tweet2index[tweet] = i\n",
    "    \n",
    "y = np.array([tweet2index[x] for x in text])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2404"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener la matriz TF-IDF de los tweets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_1 = TfidfVectorizer(tokenizer=clean_tokens, stop_words='english').fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3108, 7276)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(clf, X, y):\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"%s accuracy: %0.2f (+/- %0.2f)\" % \\\n",
    "          (str(clf.__class__).split('.')[-1].replace('>','').replace(\"'\",''), \n",
    "          scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(X, y):\n",
    "    run_model(SGDClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3108, 7276) (3108,)\n"
     ]
    }
   ],
   "source": [
    "print(X_1.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-825065166f8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-f7b8ff22da4f>\u001b[0m in \u001b[0;36mrun_models\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-7f4a5ccd5837>\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(clf, X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     print(\"%s accuracy: %0.2f (+/- %0.2f)\" %           (str(clf.__class__).split('.')[-1].replace('>','').replace(\"'\",''), \n\u001b[0;32m      4\u001b[0m           scores.mean(), scores.std() * 2))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "run_models(X_1, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando Word Vectors de Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=6\n",
    "spacy_vectors = np.identity(m)\n",
    "spacy_vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86091788 0.82998004 0.83301083 0.65290201 0.70461497 0.8410422 ]\n",
      " [0.62335627 0.83674718 0.80756677 0.58320796 0.82678588 0.8056291 ]\n",
      " [0.72087494 0.07278065 0.24754889 0.48471839 0.91473282 0.99213188]]\n",
      "[[0.40633864 0.96276768 0.85424681]\n",
      " [0.42258866 0.62476255 0.66817416]\n",
      " [0.04056099 0.72066663 0.53747064]\n",
      " [0.88532785 0.06287056 0.0211588 ]\n",
      " [0.47363792 0.07395148 0.35004012]\n",
      " [0.81473252 0.43397874 0.23046577]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_layer = 3\n",
    "\n",
    "theta1 = np.random.rand(hidden_layer,m)\n",
    "theta2 = np.random.rand(m,hidden_layer)\n",
    "\n",
    "print(theta1)\n",
    "print(theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5515069207179557,\n",
       " 0.18667742416263217,\n",
       " 0.06829686549907661,\n",
       " 0.04947596648303089,\n",
       " 0.0006595267118710769,\n",
       " 0.14338329642543368]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ = spacy_vectors[3]\n",
    "y_ = spacy_vectors[4]\n",
    "x_ = np.matrix(x_)\n",
    "\n",
    "\n",
    "a1,a2, h = forward2(x_,theta1,theta2)\n",
    "h\n",
    "theta3,theta4 = backpropagation2(theta1,theta2,x_,y_)\n",
    "a1,a2, h = forward2(x_,theta3,theta4)\n",
    "#np.array(h)\n",
    "softmax(np.array(h)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def softmax(H):\n",
    "    sumatoria = sum([math.exp(w) for w in H])\n",
    "    return [math.exp(w)/sumatoria for w in H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,theta1,theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1=X\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = sigmoid(z2) #funcion activacion\n",
    "    z3 = a2 * theta2.T\n",
    "    h = sigmoid(z3) #funcion activacion\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward2(X,theta1,theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1=X\n",
    "    a2 = a1 * theta1.T\n",
    "    h = a2 * theta2.T\n",
    "    \n",
    "    return a1,a2, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(thetha1,theta2,X,y):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    a1, z2, a2, z3, h = forward(theta1,theta2,X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation2(theta1,theta2,X,y):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    a1,a2,h = forward2(X,theta1,theta2)\n",
    "    \n",
    "    delta1 = np.zeros(theta1.shape)  \n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    \n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]\n",
    "        a2t = a2[t,:]\n",
    "        ht = h[t,:]\n",
    "        yt = y[t,:]\n",
    "        \n",
    "        d3t = ht - yt #(1,6)\n",
    "        \n",
    "        d2t = (theta2.T * d3t.T).T #(1,3)\n",
    "        \n",
    "        delta1 = delta1 + d2t.T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    grad1 = delta1\n",
    "    grad2 = delta2\n",
    "    \n",
    "    return grad1,grad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape\n",
    "#X_test.shape\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
